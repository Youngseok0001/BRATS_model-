{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, sys\n",
    "from nets import model_cmc\n",
    "from dataset.utils import  norm_image_by_patient, eval_single\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "import SimpleITK as sitk\n",
    "import dataset.val_test_load_batch as load_batch\n",
    "from dataset.utils import writeImage, cc, postprocessing, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "post_processing = False\n",
    "checkpoint_dir = \"/home/jacob/Projects/image_segmentation/data/to_record/\"\n",
    "model = \"cmc\"\n",
    "checkpoint_dir = '/home/jacob/Projects/image_segmentation/data/to_record/'\n",
    "datasetDir = '/home/jacob/Projects/image_segmentation/data/to_record/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 240, 240, 4)\n",
      "Warning -- You have opted to use the orthogonal_initializer function\n",
      "WARNING:tensorflow:<nets.convLSTM_upgrade.ConvLSTMCell object at 0x7f34fc315198>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "(1, 15, 15, 40) (1, 15, 15, 40)\n",
      "you have initialized one orthogonal matrix.\n",
      "(1, 15, 15, 40) (1, 15, 15, 40)\n",
      "(1, 15, 15, 40) (1, 15, 15, 40)\n",
      "(1, 15, 15, 40) (1, 15, 15, 40)\n",
      "you have initialized one orthogonal matrix.\n",
      "(1, 15, 15, 40) (1, 15, 15, 40)\n",
      "(1, 15, 15, 40) (1, 15, 15, 40)\n",
      "decode net (1, 30, 30, 40) (1, 30, 30, 40)\n",
      "(1, 30, 30, 40)\n",
      "(1, 60, 60, 40)\n",
      "(1, 120, 120, 40)\n",
      "(1, 240, 240, 40)\n",
      "decode net (1, 30, 30, 40) (1, 30, 30, 40)\n",
      "(1, 30, 30, 40)\n",
      "(1, 60, 60, 40)\n",
      "(1, 120, 120, 40)\n",
      "(1, 240, 240, 40)\n",
      "decode net (1, 30, 30, 40) (1, 30, 30, 40)\n",
      "(1, 30, 30, 40)\n",
      "(1, 60, 60, 40)\n",
      "(1, 120, 120, 40)\n",
      "(1, 240, 240, 40)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def padding(im, shape=(240,240)):\n",
    "    # im 1 240-16, 240-16, 1\n",
    "    new_im = np.zeros(shape)\n",
    "    new_im[8: 240-8, 8: 240-8] = im\n",
    "    return new_im\n",
    "\n",
    "img_input = tf.placeholder(tf.float32, shape=(1, 3, 240, 240, 4))\n",
    "la_input = tf.placeholder(tf.int32, shape=(1, 3, 240, 240, 1))\n",
    "is_training =tf.placeholder(tf.bool)\n",
    "\n",
    "folder = glob.glob(datasetDir + '*test*.tfrecord')\n",
    "im_queues = {}\n",
    "for f in folder:\n",
    "    imname = f.split(\"/\")[-1].split(\".\")[0]\n",
    "    batch = load_batch.get_batch_cmc(f)\n",
    "    im_queues[imname] = batch\n",
    "\n",
    "net = model_cmc.Model()\n",
    "logits, _ = net.net(img_input, is_training)\n",
    "logits = [tf.argmax(l, axis=3) for l in logits]\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/jacob/Projects/image_segmentation/data/to_record/model.ckpt-0\n",
      "Model restore!\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Input to reshape is a tensor with 172800 values, but the requested shape has 57600\n",
      "\t [[Node: cmc/label/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cmc/label/DecodeRaw/_531, cmc/label/Reshape/shape)]]\n",
      "\t [[Node: cmc/image/transpose/_535 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_19_cmc/image/transpose\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
      "fineish one head (0,) (0,)\n",
      "finish\n",
      "SCORES:\n",
      "COMPLETE: \n",
      " [nan nan nan]\n",
      "CORE: \n",
      " [nan nan nan]\n",
      "ENHANCING: \n",
      " [0. 0. 0.]\n",
      "accuracy = nan\n",
      "mean IU  = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacob/Projects/image_segmentation/code/dataset/utils.py:52: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dice_score = np.sum(np.diag(hist)[1:])*2/float(np.sum(hist.sum(1)[1:])+np.sum(hist.sum(0)[1:]))\n",
      "/home/jacob/Projects/image_segmentation/code/dataset/utils.py:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ppv_score = np.sum(np.diag(hist)[1:])/float(np.sum(np.diag(hist)[1:])+hist[1][0])\n",
      "/home/jacob/Projects/image_segmentation/code/dataset/utils.py:54: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sens_score = np.sum(np.diag(hist)[1:])/float(np.sum(np.diag(hist)[1:])+hist[0][1])\n",
      "/home/jacob/Projects/image_segmentation/code/dataset/utils.py:74: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dice_score = np.sum(np.diag(hist)[1:])*2/float(np.sum(hist.sum(1)[1:])+np.sum(hist.sum(0)[1:]))\n",
      "/home/jacob/Projects/image_segmentation/code/dataset/utils.py:75: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ppv_score = np.sum(np.diag(hist)[1:])/float(np.sum(np.diag(hist)[1:])+hist[1][0])\n",
      "/home/jacob/Projects/image_segmentation/code/dataset/utils.py:76: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sens_score = np.sum(np.diag(hist)[1:])/float(np.sum(np.diag(hist)[1:])+hist[0][1])\n",
      "/home/jacob/.virtualenvs/3/lib/python3.6/site-packages/ipykernel_launcher.py:89: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/jacob/.virtualenvs/3/lib/python3.6/site-packages/ipykernel_launcher.py:90: RuntimeWarning: Mean of empty slice\n",
      "/home/jacob/.virtualenvs/3/lib/python3.6/site-packages/ipykernel_launcher.py:91: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/jacob/.virtualenvs/3/lib/python3.6/site-packages/ipykernel_launcher.py:92: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 172800 values, but the requested shape has 57600\n\t [[Node: cmc/label/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cmc/label/DecodeRaw/_531, cmc/label/Reshape/shape)]]\n\t [[Node: cmc/image/transpose/_535 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_19_cmc/image/transpose\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8f3dc180499b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    class # %d accuracy = %f \"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/3/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/3/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, sess, enqueue_op, coord)\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m           \u001b[0menqueue_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_closed_exception_types\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=catching-non-exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m           \u001b[0;31m# This exception indicates that a queue was closed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_single_operation_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0m_single_operation_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_tf_sessionrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_single_operation_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 172800 values, but the requested shape has 57600\n\t [[Node: cmc/label/Reshape = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cmc/label/DecodeRaw/_531, cmc/label/Reshape/shape)]]\n\t [[Node: cmc/image/transpose/_535 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_19_cmc/image/transpose\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "dir = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "saver.restore(sess, dir)\n",
    "sess.run(tf.local_variables_initializer())\n",
    "print(\"Model restore!\")\n",
    "\n",
    "num_class = 5\n",
    "hist = np.zeros((num_class, num_class))\n",
    "out_slices = []\n",
    "la_slices = []\n",
    "complete = np.array([0.0, 0.0, 0.0])\n",
    "core = np.array([0.0, 0.0, 0.0])\n",
    "enhancing = np.array([0.0, 0.0, 0.0])\n",
    "for f in folder:\n",
    "    ind = 0\n",
    "    out = []\n",
    "    la = []\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    imname = f.split(\"/\")[-1].split(\".\")[0]\n",
    "    batch = im_queues[imname]\n",
    "    try:\n",
    "        while not coord.should_stop():\n",
    "            ind += 1\n",
    "            image_batch_seq = []\n",
    "            label_batch_seq = []\n",
    "            if (ind == 52):\n",
    "                image_batch_seq.append(prev_image)\n",
    "                label_batch_seq.append(prev_label)\n",
    "                for _ in range(2):\n",
    "                    image_batch, label_batch = sess.run(batch)\n",
    "                    image_batch_seq.append(image_batch)\n",
    "                    label_batch_seq.append(label_batch)\n",
    "            else:\n",
    "                for _ in range(3):\n",
    "                    image_batch, label_batch = sess.run(batch)\n",
    "                    image_batch_seq.append(image_batch)\n",
    "                    label_batch_seq.append(label_batch)\n",
    "                # 3,1,240,240,4\n",
    "            prev_image = image_batch\n",
    "            prev_label = label_batch\n",
    "            image_batch = np.array(image_batch_seq).transpose((1,0,2,3,4))\n",
    "            label_batch =  np.array(label_batch_seq)\n",
    "            pred = sess.run(logits, feed_dict={\n",
    "                img_input: image_batch, \n",
    "                is_training: False})\n",
    "                        \n",
    "            if post_processing:\n",
    "                for i in range(3):\n",
    "                    pred[i] = cc(pred[i][0])\n",
    "            else:\n",
    "                for i in range(3):\n",
    "                    pred[i] = pred[i][0]\n",
    "            #hist += eval_single(pred.astype(np.int64), label_batch, num_class)\n",
    "            if ind == 52:\n",
    "                for i in range(1,3):\n",
    "                    out.append(pred[i])\n",
    "                    la.append(label_batch[i][0][:,:,0])\n",
    "            else:\n",
    "                for i in range(3):\n",
    "                    out.append(pred[i])\n",
    "                    la.append(label_batch[i][0][:,:,0])\n",
    "    except Exception:\n",
    "        out = np.array(out).astype(np.int64)\n",
    "        la = np.array(la).astype(np.int64)\n",
    "        print(\"fineish one head\", out.shape, la.shape)\n",
    "        if post_processing:\n",
    "            out = postprocessing(out)\n",
    "        out_slices.append(out)\n",
    "        la_slices.append(la)\n",
    "        _complete, _core, _enhancing = evaluate(out, la)\n",
    "        complete += _complete\n",
    "        core += _core\n",
    "        enhancing += _enhancing\n",
    "        #outImage = sitk.GetImageFromArray(out)\n",
    "        #outImage = sitk.Cast(outImage, sitk.sitkUInt8)\n",
    "        #sitk.WriteImage(outImage, \"./results/\"+imname+\".nii\")\n",
    "        print(\"finish\")\n",
    "\n",
    "print(\"SCORES:\")\n",
    "print(\"COMPLETE: \\n\", complete/float(15))\n",
    "print(\"CORE: \\n\", core/float(15))\n",
    "print(\"ENHANCING: \\n\", enhancing/float(15))\n",
    "\n",
    "for ss, las in zip(out_slices, la_slices):\n",
    "    for s, l in zip(ss, las):\n",
    "        hist += eval_single(s.astype(np.int64), l, num_class)\n",
    "\n",
    "acc_total = np.diag(hist).sum() / hist.sum()\n",
    "print ('accuracy = %f'%np.nanmean(acc_total))\n",
    "iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist))\n",
    "print ('mean IU  = %f'%np.nanmean(iu))\n",
    "for ii in range(num_class):\n",
    "    if float(hist.sum(1)[ii]) == 0:\n",
    "        acc = 0.0\n",
    "    else:\n",
    "        acc = np.diag(hist)[ii] / float(hist.sum(1)[ii])\n",
    "        print(\"    class # %d accuracy = %f \"%(ii, acc))\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
